# Enhancing Out-of-Distribution Detection via Boundary-Constrained Generative Adversarial Networks

The core code is located in ./train_bcood.py.

## 1.   Algorithm Overview

The BCOOD method is a novel OOD detection method via Boundary-Constrained Generative Adversarial Networks. The core innovation lies in generating difficult OOD samples that simultaneously satisfy two critical criteria: proximity to low-density areas of in-distribution (ID) data and sufficient diversity in the feature space.



## 2.   Network Architecture

**A.**  **Generator**

Structure:

(1) A fully connected layer upscales the latent vector to an appropriate dimension.

(2) Transposed convolutional layers perform upsampling.

(3) Batch normalization and LeakyReLU activation functions are used. The final output is constrained to the range [-1, 1] using a Tanh activation function.

**B.**  **Discriminator**

Structure:

(1) Convolutional blocks extract features (including convolution, batch normalization, 

LeakyReLU, and Dropout).

(2) Two output heads:
Adversarial head: Determines input authenticity (binary classification).
Auxiliary head: Performs category classification (multi-class classification).



## 3.   Fast Sampling Module

```python  
def sample_zid(self, batch_size):  
    """Sample ID latent variables from a GMM"""  
    # 1. Randomly select Gaussian components  
    comp_idx = torch.randint(0, 10, (batch_size,))  
    # 2. Sample from the selected components  
    z = torch.randn(batch_size, latent_dim).to(self.device)  
    z = self.gmm_means[comp_idx] + z * torch.sqrt(self.gmm_vars[comp_idx])  
    return z, comp_idx  # Return latent variables and corresponding labels
```

Implementation Key Points:

(1) Use a Gaussian Mixture Model (GMM) to model the latent representation of ID data.

(2) Each Gaussian component corresponds to a semantic category.

(3) Ensure structured representation in the latent space.



## 4.   Difficult OOD Data Generation Module

**1.**   **Introducing FGSM into GAN (Perturbing the Generator’s Output)**

```python
def fgsm_attack(self, data, data_labels, epsilon):  
    """Basic FGSM attack to generate adversarial examples"""  
    data.requires_grad = True  
    # Forward pass to compute loss  
    validity, pred_labels, _ = self.discriminator(data)  
    loss = self.auxiliary_loss(pred_labels, data_labels)  
    # Backward pass to obtain gradients  
    loss.backward()  
    data_grad = data.grad.data  
    # Add perturbation along the gradient direction  
    perturbed_data = data + epsilon * torch.sign(data_grad)  
    return perturbed_data.detach()  
```



**2.**   **Improved FGSM: Adding Directional Parameters to FGSM**

```python
def diversity_enhanced_fgsm(self, data, data_labels, epsilon_mean, epsilon_std):  
    """FGSM with directional parameters - enhances local diversity"""  
    data.requires_grad = True  
    # Forward pass  
    validity, pred_labels, _ = self.discriminator(data)  
    loss = self.auxiliary_loss(pred_labels, data_labels)  
    # Obtain gradients  
    self.discriminator.zero_grad()  
    loss.backward()  
    data_grad = data.grad.data  
    # Sample different ε for each dimension  
    epsilon = torch.normal(epsilon_mean, epsilon_std, size=data_grad.shape).to(self.device)  
    epsilon = torch.clamp(epsilon, 0.01, 0.05)  # Clamp to a reasonable range  
    # Apply diverse perturbations (no longer uniform)  
    perturbed_data = data + epsilon * torch.sign(data_grad)  
    perturbed_data = torch.clamp(perturbed_data, -1, 1)  
    return perturbed_data.detach()  
```



**3.**   **Adding FGSM Perturbation to the Latent Space**

```python
def latent_space_perturbation(self, zid, labels, epsilon_mean, epsilon_std):  
    """Apply FGSM perturbation in the latent space - enhances global diversity"""  
    zid.requires_grad = True  
    # Through the generator-discriminator composite function  
    aid = self.generator(zid)  # Generate auxiliary ID data  
    validity, pred_labels, _ = self.discriminator(aid)  
    loss = self.auxiliary_loss(pred_labels, labels)  
    # Compute gradients with respect to latent variables  
    self.generator.zero_grad()  
    self.discriminator.zero_grad()  
    loss.backward()  
    zid_grad = zid.grad.data  
    # Apply FGSM perturbation to the latent space  
    epsilon = torch.normal(epsilon_mean, epsilon_std, size=zid_grad.shape).to(self.device)  
    epsilon = torch.clamp(epsilon, 0.01, 0.05)  
    zid_prime = zid - epsilon * torch.sign(zid_grad)  
    return zid_prime.detach()  
```



**4.**   **Difficult OOD Data Generation**

By integrating the three points above—i.e., combining FGSM with GAN (point 1) and designing a 

diversity enhancement mechanism (points 2 and 3)—we obtain the following two types of difficult OOD data:

(1) DOOD1: Generated by applying FGSM perturbation to the output of the GAN generator.

```python
# Generation process:  
# 1. Sample ZID from the latent space  
# 2. Generate auxiliary ID data AID = G(ZID)  
# 3. Apply diverse FGSM to AID to obtain DOOD1  

zid, zid_labels = self.sample_zid(batch_size)
aid = self.generator(zid)
dood1 = self.diversity_enhanced_fgsm(aid, zid_labels, fgsm_epsilon, fgsm_epsilon * 0.3)
```

Data characteristics: Biased towards local diversity, such as features like animal eyes and ears.

 

(2) DOOD2: Generated by perturbing the latent space.

```python
# Generation process:  
# 1. Sample ZID from the latent space  
# 2. Apply latent space FGSM to ZID to obtain ZID′  
# 3. Generate DOOD2 = G(ZID′)  

zid, zid_labels = self.sample_zid(batch_size)
zid_prime = self.latent_space_perturbation(zid, zid_labels, fgsm_epsilon, fgsm_epsilon * 0.3)
dood2 = self.generator(zid_prime)
```

Data characteristics: Biased towards global diversity, affecting high-level semantics (e.g., shape and structure).



Note: During training, the values of epsilon_mean and epsilon_std can be adjusted according to 

different epoch stages. For example, in later epochs, these values should be appropriately 

increased to achieve greater diversity.



## 5.   Data Conflict Adjustment Module

Distance Correlation Calculation

```python
def distance_correlation(self, x, y):  
    """Calculate the distance correlation between two sample sets"""  
    # Compute pairwise distance matrices  
    x_dist = torch.cdist(x, x)  
    y_dist = torch.cdist(y, y)  
    # Center the distance matrices  
    def center_distance_matrix(d):  
        row_mean = d.mean(dim=1, keepdim=True)  
        col_mean = d.mean(dim=0, keepdim=True)  
        total_mean = d.mean()  
        return d - row_mean - col_mean + total_mean  
    x_dist_centered = center_distance_matrix(x_dist)  
    y_dist_centered = center_distance_matrix(y_dist)  
    # Compute covariance  
    cov_xx = (x_dist_centered * x_dist_centered).sum() / (x.size(0) ** 2)  
    cov_yy = (y_dist_centered * y_dist_centered).sum() / (y.size(0) ** 2)  
    cov_xy = (x_dist_centered * y_dist_centered).sum() / (x.size(0) ** 2)  
    # Avoid division by zero  
    if cov_xx * cov_yy == 0:  
        return torch.tensor(0.0).to(self.device)  
    return cov_xy / torch.sqrt(cov_xx * cov_yy)  
```



Subsequently, two types of regularization terms are added to the generator loss:

(1) Latent space-feature space distance preservation: Ensures that the separation in the latent space is transferred to the feature space.

(2) Distance constraints between DOOD1 and AOOD, and DOOD2 and AOOD: Forces the generated difficult OOD data to be close to the real OOD region, thereby achieving the goal of staying away from the ID data region.

```python
# Regularization term added to the generator loss, corresponding to formula (12) in the paper  
reg_loss = -self.distance_correlation(zid, zood)  # Negative sign for minimization  
# Calculate distance correlation between DOOD1 and AOOD, corresponding to formula (13) in the paper  
reg_dood1 = self.distance_correlation(  
    dood1.view(dood1.size(0), -1),  
    aood.view(aood.size(0), -1)  
)  
# Calculate distance correlation between DOOD2 and AOOD, corresponding to formula (14) in the paper  
reg_dood2 = self.distance_correlation(  
    dood2.view(dood2.size(0), -1),  
    aood.view(aood.size(0), -1)  
) 
```



## 6.   Partial Parameter Settings

| Parameter            | Suggested Value | Description                                             |
| -------------------- | --------------- | ------------------------------------------------------- |
| latent_dim           | 100             | Latent space dimension                                  |
| batch_size           | 128             | Batch size                                              |
| lr_g, lr_d           | 0.0002          | Generator and discriminator learning  rates             |
| fgsm_epsilon         | 0.01 - 0.05     | Base strength of FGSM perturbation                      |
| lambda_reg           | 0.25            | Strength of distance preservation  regularization       |
| tau                  | 0.15            | GMM density threshold                                   |
| lambda1 (Formula 16) | 0.1 - 0.25      | Strength of DOOD1 distance constraint                   |
| lambda2(Formula 16)  | 0.05 - 0.2      | Strength of DOOD2 distance constraint                   |
| lambda3 (Formula 16) | 0.1 – 0.3       | Strength of latent-feature space distance  preservation |

 

# Program Execution

## 1.   File Structure

(1) configs folder: Stores configuration files, including parameters for some datasets (datasets), BCOOD training parameters, neural network parameters and pre-trained network parameters for comparative methods (networks), training parameters for comparative methods (pipelines), and preprocessing parameters (preprocessors).

(2) data folder: Stores downloaded datasets.

(3) models folder: Trained models are saved here.

(4) results folder: Stores experimental results.

(5) train_bcood.py file: Implementation of the BCOOD method.

## 2.   Code Environment

Experimental environment: Pycharm 2020.2.5 Community Edition, Intel(R) Core(TM) RTX 2080Ti GPU @ 3.00 GHz, 16.0 GB RAM.

python = 3.8.5

Partial dependency versions (all versions refer to the requirements.txt file):

torch==2.1.2

torchvision==0.16.2

torchaudio==2.1.2

numpy==1.26.3

scipy==1.11.4

pandas==2.1.4

scikit-learn==1.3.2

 

One-click installation of all dependencies:

pip install -r requirements.txt

## 3.   Dataset Download

The program will automatically download CIFAR-100 dataset. To manually prepare data, place the 

data in the data folder:

mkdir -p data/dataset_name

Data format: Standard PyTorch Dataset format.

Relevant dataset download URLs:

(1) Fashion-MNIST: https://github.com/zalandoresearch/fashion-mnist/tree/master

(2) CIFAR-10 and CIFAR-100: https://www.cs.toronto.edu/~kriz/cifar.html

(3) TinyImageNet: https://github.com/rmccorm4/Tiny-Imagenet-200

(4) SVHN: http://ufldl.stanford.edu/housenumbers

(5) LSUN: https://github.com/fyu/lsun (Note: We use the resized version of LSUN)

(6) Datasets used in the FS-OOD benchmark: https://github.com/Jingkang50/OpenOOD

 

Note: Each dataset should be placed in its own folder!

## 4.   Training BCOOD

Note: The parameter settings used in the comparative experiments in the paper are written in the 

corresponding YAML files and can be called directly.

 

Example of training BCOOD on the CIFAR-100 dataset (results from the paper):

```python
# When the pre-trained network is DenseNet-BC  
python train_bcood.py --config configs/BCOOD/cifar100_train_DBC.yml  

# When the pre-trained network is ResNet-34  
python train_bcood.py --config configs/BCOOD/cifar100_train_R34.yml 
```



Custom parameters are also supported for training. Use the following method:

```python
# Override parameters in the configuration file  
python train_bcood.py --config configs/BCOOD/cifar100_train_DBC.yml --epochs 250 --batch_size 64  
```

 

## 5.   Evaluation

Note: Our experiments use two benchmarks for evaluation. Therefore:
 **(1) Evaluation on the Traditional Benchmark**

Example for BCOOD:

  ```python
  python ./scripts/eval_ood.py \
      --dataset lsun,svhn \
      --root ./models/BCOOD_models/specific_model
  ```

Parameter description:

--dataset: Specifies the OOD dataset(s) to test. Multiple datasets can be specified, and the average of each evaluation metric will be calculated.

--root: Specifies the path to the trained model.

 The evaluation for other methods used in the experiments is similar—simply change the --root parameter accordingly.

**(2) Evaluation on the FS-OOD Benchmark**
Since the test set is predefined, there is no need to specify the OOD dataset. However, the ID dataset used for training must be specified. For example, for BCOOD trained on the MNIST dataset:

```python
python ./scripts/eval_fsood.py \
    --id-data mnist \
    --root ./models/BCOOD_models/specific_model  
```

Here, the --id-data parameter specifies the ID dataset used for training.

The evaluation for other methods used in the experiments is similar—simply change the --root parameter accordingly.



**The code is directly related to a manuscript submitted to The Visual Computer, and we will release it as soon as the paper is published.**

Reference Yan Xian, Hongru Chen, Ke Liu, Hong Yu. Enhancing Out-of-Distribution Detection via Boundary-Constrained Generative Adversarial Networks. The Visual Computer, 2025.